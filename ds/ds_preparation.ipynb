{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class WorkspaceHubOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7f84591de610>,\n",
      "         subscription_id=f804f2da-c27b-45ac-bf80-16d4d331776d,\n",
      "         resource_group_name=rg-mltable-profiler,\n",
      "         workspace_name=mlw-mltable-profiler)\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# ml_client = MLClient(subscription_id=\"f804f2da-c27b-45ac-bf80-16d4d331776d\",\n",
    "#                     workspace_name=\"mlw-mlopsv2clas-505prod\",\n",
    "#                     resource_group_name=\"rg-mlopsv2clas-505prod\",\n",
    "#                     credential=DefaultAzureCredential()\n",
    "#                     )\n",
    "# ml_client = MLClient(subscription_id = \"e62983d6-29cb-4435-b8d2-b19887c7a735\",\n",
    "#                      resource_group_name = \"mltable_PoC\",\n",
    "#                      workspace_name = \"mltable_poc\",\n",
    "#                     credential=DefaultAzureCredential()\n",
    "#                     )\n",
    "\n",
    "# --subscription f804f2da-c27b-45ac-bf80-16d4d331776d --resource-group rg-mltable-profiler --workspace-name mlw-mltable-profiler\n",
    "\n",
    "ml_client = MLClient(subscription_id = \"f804f2da-c27b-45ac-bf80-16d4d331776d\",\n",
    "                     resource_group_name = \"rg-mltable-profiler\",\n",
    "                     workspace_name = \"mlw-mltable-profiler\",\n",
    "                     credential=DefaultAzureCredential()\n",
    "                        )\n",
    "print(ml_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list datasets in the workspace\n",
    "datasets = ml_client.data.list()\n",
    "for dataset in datasets:\n",
    "    if dataset.type == \"mltable\":\n",
    "        print(dataset.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "def build_pair_list(images_dir, masks_dir, \n",
    "                    images_filename_pattern, masks_filename_pattern):\n",
    "    \"\"\"Builds a list of pairs of paths to image/mask.\n",
    "\n",
    "    Returns:\n",
    "        image_masks_pairs (List[tuple(str, str)])\n",
    "    \"\"\"\n",
    "    parsing_stats = {\n",
    "        \"masks_not_matching\": 0,\n",
    "        \"images_not_matching\": 0,\n",
    "        \"images_without_masks\": 0,\n",
    "    }\n",
    "    # search for all masks matching file name pattern\n",
    "    masks_filename_pattern = re.compile(masks_filename_pattern)\n",
    "\n",
    "    masks_paths = []\n",
    "    for file_path in glob.glob(masks_dir + \"/**/*\", recursive=True):\n",
    "        matches = masks_filename_pattern.match(os.path.basename(file_path))\n",
    "        if matches:\n",
    "            masks_paths.append((matches.group(1), file_path))\n",
    "        else:\n",
    "            # keep some stats\n",
    "            parsing_stats[\"masks_not_matching\"] += 1\n",
    "    masks_paths = dict(masks_paths)  # turn list of tuples into a map\n",
    "\n",
    "    # search for all images matching file name pattern\n",
    "    images_filename_pattern = re.compile(images_filename_pattern)\n",
    "    images_paths = []\n",
    "    for file_path in glob.glob(images_dir + \"/**/*\", recursive=True):\n",
    "        matches = images_filename_pattern.match(os.path.basename(file_path))\n",
    "        if matches:\n",
    "            images_paths.append((matches.group(1), file_path))\n",
    "        else:\n",
    "            # keep some stats\n",
    "            parsing_stats[\"images_not_matching\"] += 1\n",
    "\n",
    "    # now match images and masks\n",
    "    images = []  # list of images\n",
    "    masks = []  # list of masks (ordered like images)\n",
    "    image_masks_pairs = []  # list of tuples\n",
    "\n",
    "    for image_key, image_path in images_paths:\n",
    "        if image_key in masks_paths:\n",
    "            images.append(image_path)\n",
    "            masks.append(masks_paths[image_key])\n",
    "            image_masks_pairs.append((image_key, image_path, masks_paths[image_key]))\n",
    "        else:\n",
    "            print(\n",
    "                f\"Image {image_path} doesn't have a corresponding mask.\"\n",
    "            )\n",
    "            # keep some stats\n",
    "            parsing_stats[\"images_without_masks\"] += 1\n",
    "\n",
    "    parsing_stats[\"found_pairs\"] = len(image_masks_pairs)\n",
    "\n",
    "    print(f\"Finished parsing images/masks paths: {parsing_stats}\")\n",
    "\n",
    "    return image_masks_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished parsing images/masks paths: {'masks_not_matching': 0, 'images_not_matching': 3, 'images_without_masks': 0, 'found_pairs': 7390}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Abyssinian_1',\n",
       "  './data/images/Abyssinian_1.jpg',\n",
       "  './data/annotations/trimaps/Abyssinian_1.png'),\n",
       " ('Abyssinian_10',\n",
       "  './data/images/Abyssinian_10.jpg',\n",
       "  './data/annotations/trimaps/Abyssinian_10.png'),\n",
       " ('Abyssinian_100',\n",
       "  './data/images/Abyssinian_100.jpg',\n",
       "  './data/annotations/trimaps/Abyssinian_100.png'),\n",
       " ('Abyssinian_101',\n",
       "  './data/images/Abyssinian_101.jpg',\n",
       "  './data/annotations/trimaps/Abyssinian_101.png'),\n",
       " ('Abyssinian_102',\n",
       "  './data/images/Abyssinian_102.jpg',\n",
       "  './data/annotations/trimaps/Abyssinian_102.png')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_masks_pairs = build_pair_list(images_dir=\"./data/images/\", \n",
    "                                    masks_dir=\"./data/annotations/trimaps/\", \n",
    "                                    images_filename_pattern = \"(.*)\\\\.jpg\",\n",
    "                                    masks_filename_pattern = \"(.*)\\\\.png\"\n",
    "                                    )\n",
    "image_masks_pairs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creation_context:\n",
      "  created_at: '2023-09-14T06:15:04.361758+00:00'\n",
      "  created_by: Ali Bina\n",
      "  created_by_type: User\n",
      "  last_modified_at: '2023-09-14T06:15:04.370483+00:00'\n",
      "description: OXFORD-IIIT PET Dataset\n",
      "id: /subscriptions/f804f2da-c27b-45ac-bf80-16d4d331776d/resourceGroups/rg-mltable-profiler/providers/Microsoft.MachineLearningServices/workspaces/mlw-mltable-profiler/data/pet_images/versions/1\n",
      "name: pet_images\n",
      "path: azureml://subscriptions/f804f2da-c27b-45ac-bf80-16d4d331776d/resourcegroups/rg-mltable-profiler/workspaces/mlw-mltable-profiler/datastores/workspaceblobstore/paths/LocalUpload/e96e8f00a277573a37b4ac32dec5a077/data/\n",
      "properties: {}\n",
      "tags: {}\n",
      "type: uri_folder\n",
      "version: '1'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "dataset_parent_dir = \".\"\n",
    "images_dir=\"./data/images/\", \n",
    "masks_dir=\"./data/annotations/trimaps/\", \n",
    "images_filename_pattern = \"(.*)\\\\.jpg\",\n",
    "masks_filename_pattern = \"(.*)\\\\.png\"\n",
    "images_ds = \"pet_images\"\n",
    "dataset_dir = \"./data\"\n",
    "                                    \n",
    "\n",
    "# We'll copy each JSONL file within its related MLTable folder\n",
    "training_mltable_path = os.path.join(dataset_parent_dir, \"mltable-folder\")\n",
    "\n",
    "# First, let's create the folders if they don't exist\n",
    "os.makedirs(training_mltable_path, exist_ok=True)\n",
    "\n",
    "# Path to the training and validation files\n",
    "train_annotations_file = os.path.join(training_mltable_path, \"image_mask.jsonl\")\n",
    "\n",
    "\n",
    "index = 0\n",
    "# Scan each sub directary and generate a jsonl line per image, distributed on train and valid JSONL files\n",
    "with open(train_annotations_file, \"w\") as jsonl:\n",
    "        \n",
    "    uri_folder_data_asset = ml_client.data.get(name=images_ds, version=1)\n",
    "    print(uri_folder_data_asset)\n",
    "    # Baseline of json line dictionary\n",
    "    json_line_sample = {\n",
    "        \"image_url\": uri_folder_data_asset.path+\"/images/\",\n",
    "        \"mask_url\": uri_folder_data_asset.path+\"/annotations/trimaps/\",\n",
    "    }\n",
    "\n",
    "    # Iterate over each image mask pair\n",
    "    for image_key, image, mask in image_masks_pairs:\n",
    "        json_line = dict(json_line_sample)\n",
    "        json_line[\"image_url\"] += f\"{image_key}\"\n",
    "        json_line[\"mask_url\"] += f\"{image_key}\"\n",
    "\n",
    "        jsonl.write(json.dumps(json_line) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
