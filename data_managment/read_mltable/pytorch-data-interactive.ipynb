{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ”¥Using Azure ML Datastore URIs with PyTorch DataPipes\n",
        "\n",
        "This shows how you can seamlessly use Azure ML Datastore URIs in PyTorch DataPipes. The `azureml` fsspec implementation uses the Azure ML data runtime capability, which is fast and highly efficient for ML tasks.\n",
        "\n",
        "## What are PyTorch DataPipes?\n",
        "\n",
        "Early on, we observed widespread confusion between the PyTorch `Dataset` which represented reusable loading tooling (e.g. TorchVision's `ImageFolder`), and those that represented pre-built iterators/accessors over actual data corpora (e.g. TorchVision's ImageNet). This led to an unfortunate pattern of siloed inheritance of data tooling rather than composition.\n",
        "\n",
        "DataPipe is simply a renaming and repurposing of the PyTorch `Dataset` for composed usage. A DataPipe takes in some access function over Python data structures, `__iter__` for `IterDataPipes` and `__getitem__` for `MapDataPipes`, and returns a new access function with a slight transformation applied. For example, take a look at this `JsonParser`, which accepts an `IterDataPipe` over file names and raw streams, and produces a new iterator over the filenames and deserialized data:\n",
        "\n",
        "```python\n",
        "import json\n",
        "\n",
        "class JsonParserIterDataPipe(IterDataPipe):\n",
        "    def __init__(self, source_datapipe, **kwargs) -> None:\n",
        "        self.source_datapipe = source_datapipe\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "    def __iter__(self):\n",
        "        for file_name, stream in self.source_datapipe:\n",
        "            data = stream.read()\n",
        "            yield file_name, json.loads(data, **self.kwargs)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.source_datapipe)\n",
        "```\n",
        "\n",
        "You can see in this example how DataPipes can be easily chained together to compose graphs of transformations that reproduce sophisticated data pipelines, with streamed operation as a first-class citizen.\n",
        "\n",
        "Under this naming convention, `Dataset` simply refers to a graph of `DataPipes`, and a dataset module like `ImageNet` can be rebuilt as a factory function returning the requisite composed DataPipes. Note that the vast majority of initial support is focused on `IterDataPipes`, while more `MapDataPipes` support will come later."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the URI to read\n",
        "Here we define the Azure ML URI to read. It is the famours CIFAR10 dataset in tar format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1673425796303
        },
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "cifar_uri = \"azureml://subscriptions/5b0bd56f-84b3-4ec2-b7a1-41fd06c7edd3/resourcegroups/azureml-rg/workspaces/azureml-ws-dev/datastores/adls/paths/cifar-10-python.tar.gz\"\n",
        "titanic_uri = \"azureml://subscriptions/5b0bd56f-84b3-4ec2-b7a1-41fd06c7edd3/resourcegroups/azureml-rg/workspaces/azureml-ws-dev/datastores/adls/paths/titanic.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1673885349540
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Protocol not known: azureml\nThis exception is thrown by __iter__ of FSSpecFileListerIterDataPipe(masks='')",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/mnt/c/Users/alibina/source/repos/Bosch/mltable_profiling/data_managment/read_mltable/pytorch-data-interactive.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/alibina/source/repos/Bosch/mltable_profiling/data_managment/read_mltable/pytorch-data-interactive.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m titanic_uri \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mazureml://subscriptions/5b0bd56f-84b3-4ec2-b7a1-41fd06c7edd3/resourcegroups/azureml-rg/workspaces/azureml-ws-dev/datastores/adls/paths/titanic\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/alibina/source/repos/Bosch/mltable_profiling/data_managment/read_mltable/pytorch-data-interactive.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m dp \u001b[39m=\u001b[39m IterableWrapper([titanic_uri])\u001b[39m.\u001b[39mlist_files_by_fsspec()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/alibina/source/repos/Bosch/mltable_profiling/data_managment/read_mltable/pytorch-data-interactive.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlist\u001b[39;49m(dp))\n",
            "File \u001b[0;32m~/miniconda3/envs/promptflow/lib/python3.11/site-packages/torch/utils/data/datapipes/_hook_iterator.py:173\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     datapipe\u001b[39m.\u001b[39m_number_of_samples_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "File \u001b[0;32m~/miniconda3/envs/promptflow/lib/python3.11/site-packages/torchdata/datapipes/iter/load/fsspec.py:75\u001b[0m, in \u001b[0;36mFSSpecFileListerIterDataPipe.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39mstr\u001b[39m]:\n\u001b[1;32m     74\u001b[0m     \u001b[39mfor\u001b[39;00m root \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[0;32m---> 75\u001b[0m         fs, path \u001b[39m=\u001b[39m fsspec\u001b[39m.\u001b[39;49mcore\u001b[39m.\u001b[39;49murl_to_fs(root, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs_for_connection)\n\u001b[1;32m     77\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fs\u001b[39m.\u001b[39mprotocol, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     78\u001b[0m             protocol_list \u001b[39m=\u001b[39m [fs\u001b[39m.\u001b[39mprotocol]\n",
            "File \u001b[0;32m~/miniconda3/envs/promptflow/lib/python3.11/site-packages/fsspec/core.py:377\u001b[0m, in \u001b[0;36murl_to_fs\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m known_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    366\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mauto_mkdir\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    367\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mnum\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    375\u001b[0m }\n\u001b[1;32m    376\u001b[0m kwargs \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m known_kwargs}\n\u001b[0;32m--> 377\u001b[0m chain \u001b[39m=\u001b[39m _un_chain(url, kwargs)\n\u001b[1;32m    378\u001b[0m inkwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m    379\u001b[0m \u001b[39m# Reverse iterate the chain, creating a nested target_* structure\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/promptflow/lib/python3.11/site-packages/fsspec/core.py:325\u001b[0m, in \u001b[0;36m_un_chain\u001b[0;34m(path, kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[39mfor\u001b[39;00m bit \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(bits):\n\u001b[1;32m    324\u001b[0m     protocol \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mprotocol\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m split_protocol(bit)[\u001b[39m0\u001b[39m] \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 325\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m get_filesystem_class(protocol)\n\u001b[1;32m    326\u001b[0m     extra_kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_get_kwargs_from_urls(bit)\n\u001b[1;32m    327\u001b[0m     kws \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(protocol, {})\n",
            "File \u001b[0;32m~/miniconda3/envs/promptflow/lib/python3.11/site-packages/fsspec/registry.py:231\u001b[0m, in \u001b[0;36mget_filesystem_class\u001b[0;34m(protocol)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m protocol \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m registry:\n\u001b[1;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m protocol \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m known_implementations:\n\u001b[0;32m--> 231\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mProtocol not known: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m protocol)\n\u001b[1;32m    232\u001b[0m     bit \u001b[39m=\u001b[39m known_implementations[protocol]\n\u001b[1;32m    233\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
            "\u001b[0;31mValueError\u001b[0m: Protocol not known: azureml\nThis exception is thrown by __iter__ of FSSpecFileListerIterDataPipe(masks='')"
          ]
        }
      ],
      "source": [
        "from torchdata.datapipes.iter import IterableWrapper\n",
        "\n",
        "titanic_uri = \"azureml://subscriptions/5b0bd56f-84b3-4ec2-b7a1-41fd06c7edd3/resourcegroups/azureml-rg/workspaces/azureml-ws-dev/datastores/adls/paths/titanic\"\n",
        "\n",
        "dp = IterableWrapper([titanic_uri]).list_files_by_fsspec()\n",
        "print(list(dp))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Some simple loading examples\n",
        "\n",
        "### Load a tar file\n",
        "\n",
        "Below is an example of loading a tar file from the AzureML datastore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1673425825236
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "azureml:/subscriptions/5b0bd56f-84b3-4ec2-b7a1-41fd06c7edd3/resourcegroups/azureml-rg/workspaces/azureml-ws-dev/datastores/adls/paths/cifar-10-python.tar.gz/cifar-10-batches-py/data_batch_4\n",
            "azureml:/subscriptions/5b0bd56f-84b3-4ec2-b7a1-41fd06c7edd3/resourcegroups/azureml-rg/workspaces/azureml-ws-dev/datastores/adls/paths/cifar-10-python.tar.gz/cifar-10-batches-py/readme.html\n",
            "azureml:/subscriptions/5b0bd56f-84b3-4ec2-b7a1-41fd06c7edd3/resourcegroups/azureml-rg/workspaces/azureml-ws-dev/datastores/adls/paths/cifar-10-python.tar.gz/cifar-10-batches-py/test_batch\n",
            "azureml:/subscriptions/5b0bd56f-84b3-4ec2-b7a1-41fd06c7edd3/resourcegroups/azureml-rg/workspaces/azureml-ws-dev/datastores/adls/paths/cifar-10-python.tar.gz/cifar-10-batches-py/data_batch_3\n",
            "azureml:/subscriptions/5b0bd56f-84b3-4ec2-b7a1-41fd06c7edd3/resourcegroups/azureml-rg/workspaces/azureml-ws-dev/datastores/adls/paths/cifar-10-python.tar.gz/cifar-10-batches-py/batches.meta\n",
            "azureml:/subscriptions/5b0bd56f-84b3-4ec2-b7a1-41fd06c7edd3/resourcegroups/azureml-rg/workspaces/azureml-ws-dev/datastores/adls/paths/cifar-10-python.tar.gz/cifar-10-batches-py/data_batch_2\n",
            "azureml:/subscriptions/5b0bd56f-84b3-4ec2-b7a1-41fd06c7edd3/resourcegroups/azureml-rg/workspaces/azureml-ws-dev/datastores/adls/paths/cifar-10-python.tar.gz/cifar-10-batches-py/data_batch_5\n",
            "azureml:/subscriptions/5b0bd56f-84b3-4ec2-b7a1-41fd06c7edd3/resourcegroups/azureml-rg/workspaces/azureml-ws-dev/datastores/adls/paths/cifar-10-python.tar.gz/cifar-10-batches-py/data_batch_1\n"
          ]
        }
      ],
      "source": [
        "from torchdata.datapipes.iter import IterableWrapper\n",
        "\n",
        "dp = IterableWrapper([cifar_uri]) \\\n",
        "        .open_files_by_fsspec(mode=\"rb\") \\\n",
        "        .load_from_tar()\n",
        "\n",
        "for path, filestream in dp:\n",
        "    print(path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load a CSV file\n",
        "\n",
        "Below shows loading a CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'label': array(0, dtype=int32), 'data': array([ 3., 22.], dtype=float32)}, {'label': array(1, dtype=int32), 'data': array([ 1., 38.], dtype=float32)}, {'label': array(1, dtype=int32), 'data': array([ 3., 26.], dtype=float32)}]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from torchdata.datapipes.iter import IterableWrapper\n",
        "\n",
        "def row_processer(row):\n",
        "        # if missing age, set to 50\n",
        "        if row[5] == \"\":\n",
        "            row[5] = 50.0\n",
        "        return {\"label\": np.array(row[1], np.int32), \"data\": np.array([row[2],row[5]], dtype=np.float32)}\n",
        "\n",
        "dp = IterableWrapper([titanic_uri]) \\\n",
        "        .open_files_by_fsspec() \\\n",
        "        .parse_csv(delimiter=\",\", skip_lines=1) \\\n",
        "        .map(row_processer)\n",
        "\n",
        "print(list(dp)[:3])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A more in-depth example\n",
        "\n",
        "### Define functions to parse data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import io\n",
        "import pathlib\n",
        "import numpy as np\n",
        "from typing import cast, Tuple, Dict, Any, Iterator\n",
        "from torchdata.datapipes.iter import IterDataPipe\n",
        "from torchdata.datapipes import functional_datapipe\n",
        "\n",
        "\n",
        "# is this a data file\n",
        "def is_data_file(data: Tuple[str, Any]) -> bool:\n",
        "    path = pathlib.Path(data[0])\n",
        "    return path.name.startswith(\"data\")\n",
        "\n",
        "# function to unpickle file and cast to a dict\n",
        "def unpickle(data: Tuple[str, io.BytesIO]) -> Dict[str, Any]:\n",
        "    filename, file = data\n",
        "    content = cast(Dict[str, Any], pickle.load(file, encoding=\"latin1\"))\n",
        "    file.close()\n",
        "    return content\n",
        "\n",
        "@functional_datapipe(\"read_cifar\")\n",
        "class CifarFileReader(IterDataPipe[Tuple[np.ndarray, int]]):\n",
        "    def __init__(self, datapipe: IterDataPipe[Dict[str, Any]], *, labels_key: str) -> None:\n",
        "        self.datapipe = datapipe\n",
        "        self.labels_key = labels_key\n",
        "\n",
        "    def __iter__(self) -> Iterator[Tuple[np.ndarray, int]]:\n",
        "        for mapping in self.datapipe:\n",
        "            image_arrays = np.float32(mapping[\"data\"].reshape((-1, 3, 32, 32))/255.0)\n",
        "            category_idcs = mapping[self.labels_key]\n",
        "            yield from iter(zip(image_arrays, category_idcs))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create the data pipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'cifar_uri' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/alibina/Mlops-cli2-classic/data-science/experiment/bosch/data_managment/read_mltable/pytorch-data-interactive.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66383034663264612d633237622d343561632d626638302d3136643464333331373736642f7265736f7572636547726f7570732f72672d6d6c6f70737632636c61732d35303570726f642f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c772d6d6c6f70737632636c61732d35303570726f642f636f6d70757465732f616c6962696e6138/home/azureuser/cloudfiles/code/Users/alibina/Mlops-cli2-classic/data-science/experiment/bosch/data_managment/read_mltable/pytorch-data-interactive.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39miter\u001b[39;00m \u001b[39mimport\u001b[39;00m IterableWrapper\n\u001b[0;32m----> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66383034663264612d633237622d343561632d626638302d3136643464333331373736642f7265736f7572636547726f7570732f72672d6d6c6f70737632636c61732d35303570726f642f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c772d6d6c6f70737632636c61732d35303570726f642f636f6d70757465732f616c6962696e6138/home/azureuser/cloudfiles/code/Users/alibina/Mlops-cli2-classic/data-science/experiment/bosch/data_managment/read_mltable/pytorch-data-interactive.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m dp \u001b[39m=\u001b[39m IterableWrapper(iterable\u001b[39m=\u001b[39m[cifar_uri]) \\\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66383034663264612d633237622d343561632d626638302d3136643464333331373736642f7265736f7572636547726f7570732f72672d6d6c6f70737632636c61732d35303570726f642f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c772d6d6c6f70737632636c61732d35303570726f642f636f6d70757465732f616c6962696e6138/home/azureuser/cloudfiles/code/Users/alibina/Mlops-cli2-classic/data-science/experiment/bosch/data_managment/read_mltable/pytorch-data-interactive.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m.\u001b[39mopen_files_by_fsspec(mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \\\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66383034663264612d633237622d343561632d626638302d3136643464333331373736642f7265736f7572636547726f7570732f72672d6d6c6f70737632636c61732d35303570726f642f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c772d6d6c6f70737632636c61732d35303570726f642f636f6d70757465732f616c6962696e6138/home/azureuser/cloudfiles/code/Users/alibina/Mlops-cli2-classic/data-science/experiment/bosch/data_managment/read_mltable/pytorch-data-interactive.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m.\u001b[39mload_from_tar() \\\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66383034663264612d633237622d343561632d626638302d3136643464333331373736642f7265736f7572636547726f7570732f72672d6d6c6f70737632636c61732d35303570726f642f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c772d6d6c6f70737632636c61732d35303570726f642f636f6d70757465732f616c6962696e6138/home/azureuser/cloudfiles/code/Users/alibina/Mlops-cli2-classic/data-science/experiment/bosch/data_managment/read_mltable/pytorch-data-interactive.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m.\u001b[39mfilter(is_data_file) \\\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66383034663264612d633237622d343561632d626638302d3136643464333331373736642f7265736f7572636547726f7570732f72672d6d6c6f70737632636c61732d35303570726f642f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c772d6d6c6f70737632636c61732d35303570726f642f636f6d70757465732f616c6962696e6138/home/azureuser/cloudfiles/code/Users/alibina/Mlops-cli2-classic/data-science/experiment/bosch/data_managment/read_mltable/pytorch-data-interactive.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m.\u001b[39mmap(unpickle) \\\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f66383034663264612d633237622d343561632d626638302d3136643464333331373736642f7265736f7572636547726f7570732f72672d6d6c6f70737632636c61732d35303570726f642f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f6d6c772d6d6c6f70737632636c61732d35303570726f642f636f6d70757465732f616c6962696e6138/home/azureuser/cloudfiles/code/Users/alibina/Mlops-cli2-classic/data-science/experiment/bosch/data_managment/read_mltable/pytorch-data-interactive.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m.\u001b[39mread_cifar(labels_key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cifar_uri' is not defined"
          ]
        }
      ],
      "source": [
        "from torchdata.datapipes.iter import IterableWrapper\n",
        "\n",
        "dp = IterableWrapper(iterable=[cifar_uri]) \\\n",
        "    .open_files_by_fsspec(mode='rb') \\\n",
        "    .load_from_tar() \\\n",
        "    .filter(is_data_file) \\\n",
        "    .map(unpickle) \\\n",
        "    .read_cifar(labels_key=\"labels\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Leveraging DataPipe in `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels batch shape: torch.Size([5])\n",
            "Feature batch shape: torch.Size([5, 3, 32, 32])\n",
            "labels = tensor([0, 6, 0, 2, 7])\n",
            "features = tensor([[[[0.6980, 0.6980, 0.6980,  ..., 0.6667, 0.6588, 0.6471],\n",
            "          [0.7059, 0.7020, 0.7059,  ..., 0.6784, 0.6706, 0.6588],\n",
            "          [0.6941, 0.6941, 0.6980,  ..., 0.6706, 0.6627, 0.6549],\n",
            "          ...,\n",
            "          [0.4392, 0.4431, 0.4471,  ..., 0.3922, 0.3843, 0.3961],\n",
            "          [0.4392, 0.4392, 0.4431,  ..., 0.4000, 0.4000, 0.4000],\n",
            "          [0.4039, 0.3922, 0.4039,  ..., 0.3608, 0.3647, 0.3569]],\n",
            "\n",
            "         [[0.6902, 0.6902, 0.6902,  ..., 0.6588, 0.6510, 0.6392],\n",
            "          [0.6980, 0.6941, 0.6980,  ..., 0.6706, 0.6627, 0.6510],\n",
            "          [0.6863, 0.6863, 0.6902,  ..., 0.6627, 0.6549, 0.6471],\n",
            "          ...,\n",
            "          [0.4196, 0.4275, 0.4314,  ..., 0.3804, 0.3686, 0.3725],\n",
            "          [0.4000, 0.4039, 0.4039,  ..., 0.3725, 0.3647, 0.3608],\n",
            "          [0.3765, 0.3647, 0.3725,  ..., 0.3294, 0.3373, 0.3294]],\n",
            "\n",
            "         [[0.7412, 0.7412, 0.7412,  ..., 0.7059, 0.6941, 0.6824],\n",
            "          [0.7490, 0.7451, 0.7490,  ..., 0.7137, 0.7059, 0.6941],\n",
            "          [0.7373, 0.7373, 0.7412,  ..., 0.7059, 0.6980, 0.6902],\n",
            "          ...,\n",
            "          [0.4196, 0.4235, 0.4314,  ..., 0.3686, 0.3647, 0.3725],\n",
            "          [0.3961, 0.4000, 0.4039,  ..., 0.3647, 0.3569, 0.3569],\n",
            "          [0.3608, 0.3529, 0.3686,  ..., 0.3137, 0.3137, 0.3020]]],\n",
            "\n",
            "\n",
            "        [[[0.1137, 0.0863, 0.0980,  ..., 0.7725, 0.7765, 0.7804],\n",
            "          [0.1216, 0.1059, 0.0667,  ..., 0.8235, 0.8196, 0.8196],\n",
            "          [0.1569, 0.1216, 0.0784,  ..., 0.8235, 0.8235, 0.8235],\n",
            "          ...,\n",
            "          [0.1765, 0.0941, 0.0627,  ..., 0.0980, 0.0941, 0.0941],\n",
            "          [0.0824, 0.0706, 0.1059,  ..., 0.1020, 0.1137, 0.1098],\n",
            "          [0.2078, 0.3176, 0.3804,  ..., 0.0863, 0.0941, 0.0902]],\n",
            "\n",
            "         [[0.1686, 0.1412, 0.1451,  ..., 0.8588, 0.8588, 0.8706],\n",
            "          [0.1804, 0.1608, 0.1137,  ..., 0.9098, 0.9059, 0.9059],\n",
            "          [0.2157, 0.1765, 0.1294,  ..., 0.9098, 0.9098, 0.9098],\n",
            "          ...,\n",
            "          [0.1490, 0.0824, 0.0549,  ..., 0.1137, 0.1098, 0.1098],\n",
            "          [0.0706, 0.0510, 0.0627,  ..., 0.1176, 0.1294, 0.1255],\n",
            "          [0.1569, 0.2431, 0.2745,  ..., 0.1020, 0.1098, 0.1059]],\n",
            "\n",
            "         [[0.0392, 0.0157, 0.0627,  ..., 0.5373, 0.5373, 0.5490],\n",
            "          [0.0353, 0.0235, 0.0235,  ..., 0.5804, 0.5804, 0.5804],\n",
            "          [0.0627, 0.0314, 0.0275,  ..., 0.5882, 0.5843, 0.5843],\n",
            "          ...,\n",
            "          [0.0902, 0.0431, 0.0275,  ..., 0.1255, 0.1216, 0.1216],\n",
            "          [0.0275, 0.0118, 0.0196,  ..., 0.1294, 0.1412, 0.1373],\n",
            "          [0.0902, 0.1490, 0.1686,  ..., 0.1137, 0.1216, 0.1176]]],\n",
            "\n",
            "\n",
            "        [[[0.1412, 0.1294, 0.0824,  ..., 0.1020, 0.1020, 0.1137],\n",
            "          [0.2157, 0.1843, 0.0588,  ..., 0.0863, 0.0902, 0.0824],\n",
            "          [0.3216, 0.3686, 0.3098,  ..., 0.1843, 0.1843, 0.1765],\n",
            "          ...,\n",
            "          [0.6235, 0.6353, 0.6510,  ..., 0.7333, 0.7255, 0.7176],\n",
            "          [0.6510, 0.6667, 0.6784,  ..., 0.7176, 0.7098, 0.7059],\n",
            "          [0.6588, 0.6706, 0.6863,  ..., 0.7137, 0.7098, 0.7059]],\n",
            "\n",
            "         [[0.2549, 0.2157, 0.1843,  ..., 0.1255, 0.1216, 0.1137],\n",
            "          [0.4196, 0.3686, 0.2471,  ..., 0.2000, 0.1922, 0.1804],\n",
            "          [0.4549, 0.4980, 0.4588,  ..., 0.3255, 0.3373, 0.3333],\n",
            "          ...,\n",
            "          [0.6275, 0.6235, 0.6275,  ..., 0.7059, 0.6902, 0.6824],\n",
            "          [0.6627, 0.6627, 0.6627,  ..., 0.6902, 0.6784, 0.6745],\n",
            "          [0.6824, 0.6784, 0.6784,  ..., 0.6902, 0.6745, 0.6745]],\n",
            "\n",
            "         [[0.4000, 0.4235, 0.4627,  ..., 0.1569, 0.1216, 0.1216],\n",
            "          [0.4706, 0.4235, 0.4431,  ..., 0.4118, 0.3922, 0.3804],\n",
            "          [0.4471, 0.4000, 0.4235,  ..., 0.6000, 0.6118, 0.6000],\n",
            "          ...,\n",
            "          [0.5804, 0.5843, 0.5922,  ..., 0.6941, 0.6824, 0.6745],\n",
            "          [0.6275, 0.6314, 0.6353,  ..., 0.6824, 0.6706, 0.6706],\n",
            "          [0.6510, 0.6549, 0.6588,  ..., 0.6784, 0.6667, 0.6667]]],\n",
            "\n",
            "\n",
            "        [[[0.1176, 0.1765, 0.1725,  ..., 0.0000, 0.1647, 0.6392],\n",
            "          [0.1333, 0.2980, 0.2275,  ..., 0.0000, 0.0706, 0.4627],\n",
            "          [0.2824, 0.4235, 0.2353,  ..., 0.0000, 0.0549, 0.4314],\n",
            "          ...,\n",
            "          [0.7922, 0.7529, 0.7725,  ..., 0.7490, 0.5922, 0.4706],\n",
            "          [0.6980, 0.6510, 0.6902,  ..., 0.6118, 0.5059, 0.4745],\n",
            "          [0.6471, 0.4902, 0.4941,  ..., 0.4706, 0.4627, 0.6196]],\n",
            "\n",
            "         [[0.2941, 0.3725, 0.3686,  ..., 0.0000, 0.1647, 0.6392],\n",
            "          [0.2824, 0.5176, 0.4824,  ..., 0.0000, 0.0706, 0.4627],\n",
            "          [0.4275, 0.6627, 0.5059,  ..., 0.0000, 0.0549, 0.4314],\n",
            "          ...,\n",
            "          [0.8510, 0.8118, 0.8706,  ..., 0.8510, 0.6353, 0.4745],\n",
            "          [0.7490, 0.6980, 0.7490,  ..., 0.6902, 0.5373, 0.4863],\n",
            "          [0.6745, 0.5216, 0.5216,  ..., 0.5098, 0.4824, 0.6275]],\n",
            "\n",
            "         [[0.0902, 0.1529, 0.1373,  ..., 0.0000, 0.1647, 0.6392],\n",
            "          [0.1059, 0.2706, 0.1922,  ..., 0.0000, 0.0706, 0.4627],\n",
            "          [0.2510, 0.3882, 0.1843,  ..., 0.0000, 0.0549, 0.4314],\n",
            "          ...,\n",
            "          [0.5647, 0.5255, 0.5608,  ..., 0.4745, 0.4275, 0.4392],\n",
            "          [0.5294, 0.4824, 0.5255,  ..., 0.4471, 0.3765, 0.4235],\n",
            "          [0.5765, 0.4235, 0.4235,  ..., 0.4157, 0.3882, 0.5765]]],\n",
            "\n",
            "\n",
            "        [[[0.1373, 0.3137, 0.3490,  ..., 0.6118, 0.5373, 0.6000],\n",
            "          [0.1176, 0.2471, 0.3373,  ..., 0.5647, 0.5569, 0.6039],\n",
            "          [0.1922, 0.2275, 0.3529,  ..., 0.4431, 0.4275, 0.4667],\n",
            "          ...,\n",
            "          [0.6588, 0.6706, 0.6980,  ..., 0.4941, 0.5255, 0.4863],\n",
            "          [0.6392, 0.6824, 0.7294,  ..., 0.5216, 0.4510, 0.3451],\n",
            "          [0.6510, 0.6902, 0.7373,  ..., 0.4824, 0.4784, 0.3961]],\n",
            "\n",
            "         [[0.2157, 0.3922, 0.4275,  ..., 0.7373, 0.6431, 0.6980],\n",
            "          [0.1843, 0.3216, 0.4157,  ..., 0.7137, 0.6745, 0.6980],\n",
            "          [0.2627, 0.2941, 0.4235,  ..., 0.6078, 0.5490, 0.5490],\n",
            "          ...,\n",
            "          [0.6157, 0.6314, 0.6431,  ..., 0.6196, 0.5765, 0.4784],\n",
            "          [0.6000, 0.6353, 0.6706,  ..., 0.6392, 0.5098, 0.3569],\n",
            "          [0.5804, 0.6157, 0.6431,  ..., 0.5569, 0.5216, 0.4235]],\n",
            "\n",
            "         [[0.1647, 0.3333, 0.3569,  ..., 0.6941, 0.5804, 0.6275],\n",
            "          [0.1294, 0.2510, 0.3373,  ..., 0.6863, 0.6235, 0.6235],\n",
            "          [0.1882, 0.2157, 0.3333,  ..., 0.5961, 0.5098, 0.4784],\n",
            "          ...,\n",
            "          [0.5373, 0.5333, 0.5686,  ..., 0.4353, 0.4627, 0.4235],\n",
            "          [0.5216, 0.5412, 0.5961,  ..., 0.4745, 0.4039, 0.2941],\n",
            "          [0.5373, 0.5569, 0.6039,  ..., 0.4196, 0.4314, 0.3608]]]])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dl = DataLoader(dataset=dp, batch_size=5)\n",
        "first = next(iter(dl))\n",
        "features, labels = first[0], first[1]\n",
        "print(f\"Labels batch shape: {labels.size()}\")\n",
        "print(f\"Feature batch shape: {features.size()}\")\n",
        "print(f\"{labels = }\\n{features = }\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train a model using PyTorch\n",
        "\n",
        "#### Define Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net = Net()\n",
        "net.to(device=device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define loss function and optimization strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.248\n",
            "[1,  4000] loss: 2.014\n",
            "[1,  6000] loss: 1.868\n",
            "[1,  8000] loss: 1.751\n",
            "[1, 10000] loss: 1.657\n",
            "[2,  2000] loss: 1.608\n",
            "[2,  4000] loss: 1.534\n",
            "[2,  6000] loss: 1.526\n",
            "[2,  8000] loss: 1.487\n",
            "[2, 10000] loss: 1.447\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(dl, 0):\n",
        "        # get the inputs; data is a tuple of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
